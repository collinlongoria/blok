/*
* File: temporal_reproject.comp
* Project: blok
* Author: Collin Longoria
* Created on: 12/1/2025
*/

#version 460

layout(local_size_x = 8, local_size_y = 8, local_size_z = 1) in;

// Current frame inputs
layout(binding = 0, rgba32f) uniform readonly image2D inColor;
layout(binding = 1, rgba32f) uniform readonly image2D inWorldPosition;
layout(binding = 2, rgba16f) uniform readonly image2D inNormalRoughness;

// History inputs (previous frame)
layout(binding = 3) uniform sampler2D historyColor;   // Filtered sampling for history
layout(binding = 4, rgba32f) uniform readonly image2D historyWorldPosition;
layout(binding = 5, rgba16f) uniform readonly image2D historyNormalRoughness;
layout(binding = 6, rg32f) uniform readonly image2D historyMoments;

// Outputs
layout(binding = 7, rgba32f) uniform writeonly image2D outColor;
layout(binding = 8, rg32f) uniform writeonly image2D outMoments;

// Frame data
layout(binding = 9) uniform FrameUBO {
    mat4 view;
    mat4 proj;
    mat4 invView;
    mat4 invProj;

    mat4 prevView;
    mat4 prevProj;
    mat4 prevViewProj;

    vec3 camPos;
    float deltaTime;

    vec3 prevCamPos;
    uint depth;

    uint frameCount;
    uint sampleCount;
    uint screenWidth;
    uint screenHeight;

    float temporalAlpha;
    float momentAlpha;
    float varianceClipGamma;
    float depthThreshold;

    float normalThreshold;
    float padding1;
    float padding2;
    float padding3;
} frame;

// Convert world position to previous frame's screen UV
vec2 worldToPrevUV(vec3 worldPos) {
    vec4 prevClip = frame.prevViewProj * vec4(worldPos, 1.0);
    vec3 prevNDC = prevClip.xyz / prevClip.w;
    return prevNDC.xy * 0.5 + 0.5;
}

// Check if UV is within screen bounds
bool isValidUV(vec2 uv) {
    return uv.x >= 0.0 && uv.x <= 1.0 && uv.y >= 0.0 && uv.y <= 1.0;
}

// Compute luminance
float luminance(vec3 color) {
    return dot(color, vec3(0.299, 0.587, 0.114));
}

// YCoCg color space conversion (better for temporal filtering)
vec3 RGBToYCoCg(vec3 rgb) {
    return vec3(
        0.25 * rgb.r + 0.5 * rgb.g + 0.25 * rgb.b,
        0.5 * rgb.r - 0.5 * rgb.b,
        -0.25 * rgb.r + 0.5 * rgb.g - 0.25 * rgb.b
    );
}

vec3 YCoCgToRGB(vec3 ycocg) {
    return vec3(
        ycocg.x + ycocg.y - ycocg.z,
        ycocg.x + ycocg.z,
        ycocg.x - ycocg.y - ycocg.z
    );
}

vec3 clipToAABB(vec3 color, vec3 minColor, vec3 maxColor) {
    vec3 center = 0.5 * (minColor + maxColor);
    vec3 extents = 0.5 * (maxColor - minColor);

    vec3 offset = color - center;
    vec3 ts = abs(extents) / max(abs(offset), vec3(0.0001));
    float t = min(min(ts.x, ts.y), ts.z);

    if (t < 1.0) {
        return center + offset * t;
    }
    return color;
}

// Gather neighborhood statistics for variance clipping
void gatherNeighborhood(ivec2 coord, out vec3 minColor, out vec3 maxColor, out vec3 mean) {
    vec3 m1 = vec3(0.0);  // First moment
    vec3 m2 = vec3(0.0);  // Second moment

    // 3x3 neighborhood (can expand to 5x5 for better stability)
    const int radius = 1;
    float count = 0.0;

    for (int dy = -radius; dy <= radius; dy++) {
        for (int dx = -radius; dx <= radius; dx++) {
            ivec2 sampleCoord = coord + ivec2(dx, dy);

            // Clamp to screen bounds
            sampleCoord = clamp(sampleCoord, ivec2(0), ivec2(frame.screenWidth - 1, frame.screenHeight - 1));

            vec3 sampleColor = imageLoad(inColor, sampleCoord).rgb;
            vec3 sampleYCoCg = RGBToYCoCg(sampleColor);

            m1 += sampleYCoCg;
            m2 += sampleYCoCg * sampleYCoCg;
            count += 1.0;
        }
    }

    mean = m1 / count;
    vec3 variance = (m2 / count) - (mean * mean);
    vec3 stdDev = sqrt(max(variance, vec3(0.0)));

    // Expand AABB by gamma * stddev
    float gamma = frame.varianceClipGamma;
    minColor = mean - gamma * stdDev;
    maxColor = mean + gamma * stdDev;
}

void main() {
    ivec2 coord = ivec2(gl_GlobalInvocationID.xy);

    // Bounds check
    if (coord.x >= int(frame.screenWidth) || coord.y >= int(frame.screenHeight)) {
        return;
    }

    // Load current frame data
    vec4 currentColorData = imageLoad(inColor, coord);
    vec4 worldPosData = imageLoad(inWorldPosition, coord);
    vec4 normalRoughnessData = imageLoad(inNormalRoughness, coord);

    vec3 currentColor = currentColorData.rgb;
    vec3 worldPos = worldPosData.xyz;
    float depth = worldPosData.w;
    vec3 normal = normalRoughnessData.xyz;
    float roughness = normalRoughnessData.w;

    // Reprojection
    // Find where this pixel was in the previous frame
    vec2 prevUV = worldToPrevUV(worldPos);

    // Default output (no history available)
    vec3 outputColor = currentColor;
    float historyWeight = 0.0;

    // Check if reprojection is valid
    bool validReprojection = isValidUV(prevUV) && frame.frameCount > 0;

    if (validReprojection) {
        // Sample history at reprojected location
        vec3 historyColorSample = texture(historyColor, prevUV).rgb;

        // Load history geometry for validation
        ivec2 historyCoord = ivec2(prevUV * vec2(frame.screenWidth, frame.screenHeight));
        historyCoord = clamp(historyCoord, ivec2(0), ivec2(frame.screenWidth - 1, frame.screenHeight - 1));

        vec4 historyWorldPosData = imageLoad(historyWorldPosition, historyCoord);
        vec4 historyNormalData = imageLoad(historyNormalRoughness, historyCoord);

        vec3 historyWorldPos = historyWorldPosData.xyz;
        float historyDepth = historyWorldPosData.w;
        vec3 historyNormal = historyNormalData.xyz;

        // Geometry validation
        // Depth test: reject if depths are too different
        // Compare the expected depth at this world position vs history depth
        float depthDiff = abs(depth - historyDepth) / max(depth, 0.001);
        bool depthValid = depthDiff < frame.depthThreshold;

        // Normal test: reject if normals are too different (disocclusion)
        float normalDot = dot(normal, historyNormal);
        bool normalValid = normalDot > frame.normalThreshold;

        // Combined validity
        bool geometryValid = depthValid && normalValid;

        // Variance clipping
        if (geometryValid) {
            vec3 minColor, maxColor, mean;
            gatherNeighborhood(coord, minColor, maxColor, mean);

            // Clip history color to neighborhood AABB in YCoCg space
            vec3 historyYCoCg = RGBToYCoCg(historyColorSample);
            vec3 clippedYCoCg = clipToAABB(historyYCoCg, minColor, maxColor);
            vec3 clippedHistory = YCoCgToRGB(clippedYCoCg);

            // Compute blend weight
            // Use more history (lower alpha) for smoother areas
            // Use less history (higher alpha) for high-variance areas
            float lum = luminance(currentColor);
            float historyLum = luminance(clippedHistory);

            // Adaptive alpha based on luminance difference
            float lumDiff = abs(lum - historyLum) / max(lum + historyLum, 0.001);
            float adaptiveAlpha = mix(frame.temporalAlpha, 1.0, lumDiff * lumDiff);

            // Also increase alpha (use more current frame) for rough surfaces
            // as they have higher variance naturally
            adaptiveAlpha = mix(adaptiveAlpha, adaptiveAlpha * 1.5, roughness);
            adaptiveAlpha = clamp(adaptiveAlpha, frame.temporalAlpha, 1.0);

            // Blend
            outputColor = mix(clippedHistory, currentColor, adaptiveAlpha);
            historyWeight = 1.0 - adaptiveAlpha;
        } else {
            // Invalid reprojection - use current color only
            outputColor = currentColor;
            historyWeight = 0.0;
        }
    }

    // Update moments for variance estimation (used by denoiser)

    float lum = luminance(outputColor);
    vec2 newMoments = vec2(lum, lum * lum);

    if (validReprojection && historyWeight > 0.0) {
        // Blend moments with history
        ivec2 historyCoord = ivec2(prevUV * vec2(frame.screenWidth, frame.screenHeight));
        historyCoord = clamp(historyCoord, ivec2(0), ivec2(frame.screenWidth - 1, frame.screenHeight - 1));
        vec2 prevMoments = imageLoad(historyMoments, historyCoord).rg;

        newMoments = mix(prevMoments, newMoments, frame.momentAlpha);
    }

    // Clamp to prevent NaN/Inf
    outputColor = clamp(outputColor, vec3(0.0), vec3(100.0));

    // Output
    imageStore(outColor, coord, vec4(outputColor, 1.0));
    imageStore(outMoments, coord, vec4(newMoments, 0.0, 0.0));
}
