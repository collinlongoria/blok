/*
* File: temporal_reproject.comp
* Project: blok
* Author: Collin Longoria
* Created on: 12/1/2025
*/

#version 460

layout(local_size_x = 8, local_size_y = 8, local_size_z = 1) in;

// Current frame inputs
layout(binding = 0, rgba32f) uniform readonly image2D inColor;
layout(binding = 1, rgba32f) uniform readonly image2D inWorldPosition;
layout(binding = 2, rgba16f) uniform readonly image2D inNormalRoughness;
layout(binding = 3, rg16f)   uniform readonly image2D inMotionVectors;

// History inputs (previous frame)
layout(binding = 4) uniform sampler2D prevHistoryColor;
layout(binding = 5, rg32f)  uniform readonly image2D prevMoments;
layout(binding = 6, r16f)   uniform readonly image2D prevHistoryLength;

// Previous frame geometry (for validation)
layout(binding = 7, rgba32f) uniform readonly image2D prevWorldPosition;
layout(binding = 8, rgba16f) uniform readonly image2D prevNormalRoughness;

// Outputs
layout(binding = 9, rgba32f)  uniform writeonly image2D outColor;
layout(binding = 10, rg32f)   uniform writeonly image2D outMoments;
layout(binding = 11, r16f)    uniform writeonly image2D outHistoryLength;

// Frame data
layout(binding = 12) uniform FrameUBO {
    // Current frame
    mat4 view;
    mat4 proj;
    mat4 invView;
    mat4 invProj;

    // Previous frame
    mat4 prevView;
    mat4 prevProj;
    mat4 prevViewProj;

    vec3 camPos;
    float deltaTime;

    vec3 prevCamPos;
    uint depth;

    uint frameCount;
    uint sampleCount;
    uint screenWidth;
    uint screenHeight;

    float temporalAlpha;
    float momentAlpha;
    float varianceClipGamma;
    float depthThreshold;

    float normalThreshold;
    float phiColor;
    float phiNormal;
    float phiDepth;

    int atrousIteration;
    int stepSize;
    float varianceBoost;
    int minHistoryLength;
} frame;

float luminance(vec3 color) {
    return dot(color, vec3(0.2126, 0.7152, 0.0722));
}

vec3 RGBToYCoCg(vec3 rgb) {
    return vec3(
         0.25 * rgb.r + 0.5 * rgb.g + 0.25 * rgb.b,
         0.5  * rgb.r                - 0.5  * rgb.b,
        -0.25 * rgb.r + 0.5 * rgb.g - 0.25 * rgb.b
    );
}

vec3 YCoCgToRGB(vec3 ycocg) {
    return vec3(
        ycocg.x + ycocg.y - ycocg.z,
        ycocg.x           + ycocg.z,
        ycocg.x - ycocg.y - ycocg.z
    );
}

vec3 clipToAABB(vec3 historyColor, vec3 currentMin, vec3 currentMax) {
    vec3 center = 0.5 * (currentMin + currentMax);
    vec3 extents = 0.5 * (currentMax - currentMin);

    vec3 offset = historyColor - center;
    vec3 unitOffset = offset / max(extents, vec3(0.0001));

    float maxComponent = max(max(abs(unitOffset.x), abs(unitOffset.y)), abs(unitOffset.z));

    if (maxComponent > 1.0) {
        return center + offset / maxComponent;
    }
    return historyColor;
}

// Convert world position to previous frame's screen UV
vec2 worldToPrevUV(vec3 worldPos) {
    vec4 prevClip = frame.prevViewProj * vec4(worldPos, 1.0);
    vec3 prevNDC = prevClip.xyz / prevClip.w;
    return prevNDC.xy * 0.5 + 0.5;
}

// Check if UV is within screen bounds
bool isValidUV(vec2 uv) {
    return uv.x >= 0.0 && uv.x <= 1.0 && uv.y >= 0.0 && uv.y <= 1.0;
}

// Gather neighborhood statistics for variance clipping
// now uses cross-bilateral weights for neighborhood sampling
void computeNeighborhoodStatistics(ivec2 coord, vec3 centerNormal, float centerDepth,
                                    out vec3 mean, out vec3 stdDev, out vec3 minC, out vec3 maxC) {
    vec3 m1 = vec3(0.0);
    vec3 m2 = vec3(0.0);
    vec3 minVal = vec3(1e10);
    vec3 maxVal = vec3(-1e10);
    float totalWeight = 0.0;

    // 3x3 neighborhood with edge-aware weighting
    for (int dy = -1; dy <= 1; dy++) {
        for (int dx = -1; dx <= 1; dx++) {
            ivec2 sampleCoord = coord + ivec2(dx, dy);
            sampleCoord = clamp(sampleCoord, ivec2(0), ivec2(frame.screenWidth - 1, frame.screenHeight - 1));

            vec4 sampleWorldPos = imageLoad(inWorldPosition, sampleCoord);
            vec4 sampleNormalData = imageLoad(inNormalRoughness, sampleCoord);
            float sampleDepth = sampleWorldPos.w;
            vec3 sampleNormal = sampleNormalData.xyz;

            // Edge-stopping weights - don't include samples across edges
            float depthDiff = abs(centerDepth - sampleDepth);
            float normalDot = dot(centerNormal, sampleNormal);

            // For voxels: use tight thresholds
            float depthWeight = depthDiff < (centerDepth * 0.02 + 0.1) ? 1.0 : 0.0;
            float normalWeight = normalDot > 0.9 ? 1.0 : 0.0;
            float weight = depthWeight * normalWeight;

            if (weight > 0.0) {
                vec3 sampleColor = imageLoad(inColor, sampleCoord).rgb;
                vec3 sampleYCoCg = RGBToYCoCg(sampleColor);

                m1 += sampleYCoCg * weight;
                m2 += sampleYCoCg * sampleYCoCg * weight;
                minVal = min(minVal, sampleYCoCg);
                maxVal = max(maxVal, sampleYCoCg);
                totalWeight += weight;
            }
        }
    }

    if (totalWeight > 0.0) {
        mean = m1 / totalWeight;
        vec3 variance = max(m2 / totalWeight - mean * mean, vec3(0.0));
        stdDev = sqrt(variance);
    } else {
        // Fallback to center pixel only
        vec3 centerColor = imageLoad(inColor, coord).rgb;
        mean = RGBToYCoCg(centerColor);
        stdDev = vec3(0.1); // Small default variance
        minVal = mean;
        maxVal = mean;
    }

    // Compute AABB with gamma expansion
    float gamma = frame.varianceClipGamma;
    minC = mean - gamma * stdDev;
    maxC = mean + gamma * stdDev;

    // Also clamp to actual min/max found (prevents over-expansion)
    minC = max(minC, minVal - vec3(0.05));
    maxC = min(maxC, maxVal + vec3(0.05));
}

void main() {
    ivec2 coord = ivec2(gl_GlobalInvocationID.xy);

    // Bounds check
    if (coord.x >= int(frame.screenWidth) || coord.y >= int(frame.screenHeight)) {
        return;
    }

    // Load current frame data
    vec3 currentColor = imageLoad(inColor, coord).rgb;
    vec4 worldPosData = imageLoad(inWorldPosition, coord);
    vec4 normalRoughnessData = imageLoad(inNormalRoughness, coord);

    vec3 worldPos = worldPosData.xyz;
    float depth = worldPosData.w;
    vec3 normal = normalize(normalRoughnessData.xyz);
    float roughness = normalRoughnessData.w;

    // Load motion vectors
    vec2 motionVector = imageLoad(inMotionVectors, coord).rg;

    // Compute reprojected UV
    // Method 1: Use motion vectors if available
    // Method 2: Reproject world position through previous view-projection matrix
    vec2 currentUV = (vec2(coord) + 0.5) / vec2(frame.screenWidth, frame.screenHeight);
    vec2 prevUV;

    if (length(motionVector) > 0.0001) {
        // Use motion vector
        prevUV = currentUV - motionVector;
    } else {
        // Reproject using world position
        prevUV = worldToPrevUV(worldPos);
    }

    // Initialize outputs
    vec3 outputColor = currentColor;
    float lum = luminance(currentColor);
    vec2 outputMoments = vec2(lum, lum * lum);
    float outputHistoryLength = 1.0;

    // Check if reprojection is valid
    bool validReprojection = isValidUV(prevUV) && frame.frameCount > 0;

    if (validReprojection) {
        // Sample history with bilinear interpolation
        vec3 historyColor = texture(prevHistoryColor, prevUV).rgb;

        // Load previous frame geometry for validation
        ivec2 prevCoord = ivec2(prevUV * vec2(frame.screenWidth, frame.screenHeight));
        prevCoord = clamp(prevCoord, ivec2(0), ivec2(frame.screenWidth - 1, frame.screenHeight - 1));

        vec4 prevWorldPosData = imageLoad(prevWorldPosition, prevCoord);
        vec4 prevNormalData = imageLoad(prevNormalRoughness, prevCoord);

        float prevDepth = prevWorldPosData.w;
        vec3 prevNormal = normalize(prevNormalData.xyz);

        // Geometry Validation
        // For voxels, uses absolute depth threshold
        // Depth consistency check
        float absoluteDepthThreshold = frame.depthThreshold * depth + 0.5;
        float depthDiff = abs(depth - prevDepth);
        bool depthValid = depthDiff < absoluteDepthThreshold;

        // Normal consistency check
        float normalDot = dot(normal, prevNormal);
        bool normalValid = normalDot > frame.normalThreshold;

        // World position consistency (helps with disocclusion)
        vec3 prevWorldPos = prevWorldPosData.xyz;
        float worldPosDiff = length(worldPos - prevWorldPos);
        bool worldPosValid = worldPosDiff < 2.0; // 2 voxel units tolerance

        // Combined validity
        bool geometryValid = depthValid && normalValid && worldPosValid;

        if (geometryValid) {
            vec2 prevMomentsData = imageLoad(prevMoments, prevCoord).rg;
            float prevHistLen = imageLoad(prevHistoryLength, prevCoord).r;

            // ============ Variance Clipping ============
            vec3 mean, stdDev, minC, maxC;
            computeNeighborhoodStatistics(coord, normal, depth, mean, stdDev, minC, maxC);

            vec3 historyYCoCg = RGBToYCoCg(historyColor);
            vec3 clippedYCoCg = clipToAABB(historyYCoCg, minC, maxC);
            vec3 clippedHistory = YCoCgToRGB(clippedYCoCg);
            clippedHistory = max(clippedHistory, vec3(0.0));

            // Temporal Blending
            float historyLen = prevHistLen + 1.0;

            // Base alpha from settings
            float alpha = frame.temporalAlpha;

            // Increase responsiveness for short history
            float historyFactor = 1.0 / max(historyLen, 1.0);
            alpha = max(alpha, historyFactor);

            // Reduce aggressiveness of luminance-based adjustment
            float lumCurrent = luminance(currentColor);
            float lumHistory = luminance(clippedHistory);
            float lumDiff = abs(lumCurrent - lumHistory) / max(lumCurrent + lumHistory + 0.01, 0.01);

            // Gentler luminance response
            alpha = mix(alpha, min(alpha + 0.2, 0.5), lumDiff * 0.3);
            alpha = clamp(alpha, frame.temporalAlpha, 1.0);

            // Blend colors
            outputColor = mix(clippedHistory, currentColor, alpha);

            // Moment Accumulation
            float newLum = luminance(currentColor);
            vec2 currentMoments = vec2(newLum, newLum * newLum);

            // Use consistent alpha for moments
            float momentAlpha = max(frame.momentAlpha, historyFactor);
            outputMoments = mix(prevMomentsData, currentMoments, momentAlpha);

            outputHistoryLength = min(historyLen, 64.0);
        }
        // else: keep initialized values (reset history)
    }

    // Clamp outputs
    outputColor = clamp(outputColor, vec3(0.0), vec3(100.0));
    outputMoments = clamp(outputMoments, vec2(0.0), vec2(10000.0));

    imageStore(outColor, coord, vec4(outputColor, 1.0));
    imageStore(outMoments, coord, vec4(outputMoments, 0.0, 0.0));
    imageStore(outHistoryLength, coord, vec4(outputHistoryLength, 0.0, 0.0, 0.0));
}